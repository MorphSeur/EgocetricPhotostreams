{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from testing import load_image\n",
    "import experiments as exp\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_classification_result(img_path, label):\n",
    "    img = io.imread(img_path)\n",
    "    \n",
    "    fig = plt.figure(figsize=(3, 3))\n",
    "    plt.clf()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    plt.title(label)\n",
    "    plt.imshow(np.asarray(img))\n",
    "    plt.yticks([], [])\n",
    "    plt.xticks([], [])\n",
    "    plt.show()\n",
    "\n",
    "with open('datasets/ntcir/categories.txt') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "print (datagen)\n",
    "# model = exp.resNet50_second_phase(weights='./weights.resNet50.lr_0.001.phase_2.fold_10.epoch_02.tf.hdf5')              # Shapes (100352, 21) and (2048, 21) are incompatible 1.14 2.3.1\n",
    "# model = exp.vgg16_first_phase_model(weights='imagenet')                                                                # Wrong Prediction\n",
    "# model = exp.vgg16_second_phase_model(weights='./weights.vgg-16.phase_2.fold_10.epoch_09.tf.hdf5')                      # Very bad predictions\n",
    "model = exp.inceptionV3_first_phase_model(weights='./weights.inceptionV3.lr_4e-05.phase_2.fold_10.epoch_09.tf.hdf5')\n",
    "# model = exp.vgg16_second_phase_model(weights='weights.vgg-16.RF.layers_fc1.fold_10.pkl')                               # Incompatible\n",
    "# model = exp.probabilities_plus_lstm()                                                                                  # Shape problem\n",
    "# model = exp.probabilities_plus_lstm()                                                                                  # Shape problem\n",
    "print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "img_array = []\n",
    "for x in range(2598):\n",
    "    path = \"./frames/frames/frame\" + str(x) + \".jpg\"\n",
    "    print(path)\n",
    "    \n",
    "    recognition = load_image(datagen, path, (299,299))\n",
    "    # recognition = load_image(datagen, path, (224,224))\n",
    "    # recognition = numpy.reshape(recognition, (recognition.shape[1], recognition.shape[2], recognition.shape[3]))\n",
    "    predictions = model.predict(recognition)\n",
    "    category = np.argmax(predictions)\n",
    "    labelToWrite = labels[category]\n",
    "    probabilityToWrite = predictions[(0,category)]\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    name = str(labelToWrite) + \" : \" + str(probabilityToWrite)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(img, name, (15, 15), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    r = cv2.imwrite(\"./frames/framesRec/frameRecInceV31\" + str(x) + \".jpg\", img)\n",
    "    \n",
    "    # img_array.append(img)\n",
    "    \n",
    "    # height, width, layers = img.shape\n",
    "    # size = (width, height)\n",
    "\n",
    "    # out = cv2.VideoWriter('frameRecVi2.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "    # for i in range(len(img_array)):\n",
    "        # out.write(img_array[i])\n",
    "    # out.release()\n",
    "    \n",
    "    #cv2.imshow('ImageWindow', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img_array = []\n",
    "\n",
    "for x in range(2598):\n",
    "    path = \"./frames/framesRec/frameRecInceV31\" + str(x) + \".jpg\"\n",
    "    # print(path)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width, height)\n",
    "    img = cv2.imread(path)\n",
    "    img_array.append(img)\n",
    "\n",
    "    out = cv2.VideoWriter('frameRecViInceV31.avi', cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = './frames/frames/'+'frame1.jpg'\n",
    "\n",
    "# img = load_image(datagen, image, (224,224))\n",
    "img = load_image(datagen, image, (299,299))\n",
    "\n",
    "predictions = model.predict(img)\n",
    "category = np.argmax(predictions)\n",
    "print(predictions[(0,category)])\n",
    "\n",
    "show_classification_result(image, labels[category])\n",
    "\n",
    "print(labels[category])\n",
    "name = labels[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image = './frames/frames/'+'frame1.jpg'\n",
    "\n",
    "img = cv2.imread(image)\n",
    "\n",
    "name = \"yes\"\n",
    "\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "cv2.putText(img, name, (15, 15), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "r = cv2.imwrite('tmp.jpg', img)\n",
    "#print(r)\n",
    "# cv2.imshow('ImageWindow', img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "input_movie = cv2.VideoCapture(\"frames/YDXJ0105.mkv\")\n",
    "length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_movie = cv2.VideoWriter('frames/out24122021.avi', fourcc, 29.97, (640, 360))\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "def rescale_frame(frame, percent=75):\n",
    "    scale_percent = 75\n",
    "    width = 299\n",
    "    height = 299\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "    \n",
    "#while True:\n",
    "    # Grab a single frame of video\n",
    "    # ret, frame = input_movie.read()\n",
    "    # frame_number += 1\n",
    "\n",
    "    # Quit when the input video file ends\n",
    "    # if not ret:\n",
    "        # break\n",
    "        \n",
    "for x in range(length):\n",
    "    ret, frame = input_movie.read()\n",
    "    \n",
    "    frame_number += 1\n",
    "    \n",
    "    img = rescale_frame(frame)\n",
    "    \n",
    "    img = numpy.reshape(img, (1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    # img = change_res(299, 299) # load_image(datagen, frame, (299,299))\n",
    "    #print(type(img))\n",
    "\n",
    "    predictions = model.predict(img)\n",
    "    category = np.argmax(predictions)\n",
    "    #print(predictions[(0,category)])\n",
    "\n",
    "    #show_classification_result(img, labels[category])\n",
    "    name = labels[category]\n",
    "    print(labels[category])\n",
    "\n",
    "    # Draw a box around the face\n",
    "    # cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "    # Draw a label with a name below the face\n",
    "    # cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(frame, name, (50, 50), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Write the resulting image to the output video file\n",
    "    print(\"Writing frame {} / {}\".format(frame_number, length))\n",
    "    output_movie.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture(\"frames/YDXJ0105.mkv\")\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "  cv2.imwrite(\"frames/frames/frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "  success,image = vidcap.read()\n",
    "  print('Read a new frame: ', success)\n",
    "  count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
